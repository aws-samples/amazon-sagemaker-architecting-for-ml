{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreaded Ensembling\n",
    "Two things are important here. Your time, and your results. Let's see if we can optimize for both! Use this notebook when you already have train, test, and validation data. Then you can train & tune a large number of models, and pull the results back in using an ensembling approach that takes the maximum prediction out of each classifier.\n",
    "\n",
    "Finally, you'll use SageMaker Search to find the best performing models from your bucket, and run multi-threaded batch transform jobs to run inference on all of your newly trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import boto3\n",
    "import os\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "import sagemaker\n",
    "from random import shuffle\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import csv\n",
    "import nltk\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Upload your train and test data sets\n",
    "Make sure you have the label in the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', names = list(range(89)))\n",
    "test = pd.read_csv('test.csv', names = list(range(89)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train[0]).astype(\"float32\")\n",
    "train_features = np.array(train.drop(0, axis=1)).astype(\"float32\")\n",
    "test_labels = np.array(test[0]).astype(\"float32\")\n",
    "test_features  = np.array(test.drop(0, axis=1)).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_estimator(clf, sess, role):\n",
    "\n",
    "    container = get_image_uri(boto3.Session().region_name, clf)\n",
    "\n",
    "    est = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, clf),\n",
    "                                    sagemaker_session=sess)\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimator(clf, sess, role):\n",
    "    \n",
    "    container = get_image_uri(boto3.Session().region_name, clf)\n",
    "\n",
    "    \n",
    "    if clf == 'xgboost':\n",
    "        est = get_base_estimator(clf, sess, role)\n",
    "        est.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)\n",
    "        \n",
    "    elif clf == 'linear-learner':\n",
    "        \n",
    "        est = sagemaker.LinearLearner(role=sagemaker.get_execution_role(),\n",
    "                                               train_instance_count=1,\n",
    "                                               train_instance_type='ml.m4.xlarge',\n",
    "                                               predictor_type='binary_classifier',\n",
    "                                               num_classes=2)\n",
    "\n",
    "    elif clf == 'knn':\n",
    "        est = sagemaker.KNN(role=sagemaker.get_execution_role(),\n",
    "                                              k = 10,\n",
    "                                               train_instance_count=1,\n",
    "                                               train_instance_type='ml.m4.xlarge',\n",
    "                                               predictor_type='classifier',\n",
    "                                                sample_size = 200)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    elif clf == 'factorization-machines':\n",
    "        est = sagemaker.FactorizationMachines(role=sagemaker.get_execution_role(),\n",
    "                                               train_instance_count=1,\n",
    "                                               train_instance_type='ml.m4.xlarge',\n",
    "                                               predictor_type='binary_classifier',\n",
    "                                                num_factors = 2)\n",
    "        \n",
    "        \n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_to_s3():\n",
    "    os.system('!aws s3 cp train.csv s3://ensemble-modeling/csv/train/train.csv')\n",
    "    os.system('!aws s3 cp test.csv s3://ensemble-modeling/csv/test/test.csv')\n",
    "    os.system('!aws s3 cp test.csv s3://ensemble-modeling/csv/validation/validation.csv')\n",
    "        \n",
    "copy_to_s3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuner(clf, est):\n",
    "        \n",
    "    if clf == 'xgboost':\n",
    "        objective_metric_name = 'validation:auc'\n",
    "\n",
    "        hyperparameter_ranges = {'eta': ContinuousParameter(0, 1),\n",
    "                        'min_child_weight': ContinuousParameter(1, 10),\n",
    "                        'alpha': ContinuousParameter(0, 2),\n",
    "                        'max_depth': IntegerParameter(1, 10)}\n",
    "        \n",
    "    elif clf == 'knn':\n",
    "        \n",
    "        objective_metric_name = 'test:accuracy'\n",
    "\n",
    "        hyperparameter_ranges = {'k': IntegerParameter(1, 1024),\n",
    "                        'sample_size': IntegerParameter(256, 20000000)}\n",
    "        \n",
    "    elif clf == 'linear-learner':\n",
    "        objective_metric_name = 'test:recall'\n",
    "        \n",
    "        hyperparameter_ranges = {'l1': ContinuousParameter(0.0000001,1),\n",
    "                            'use_bias': CategoricalParameter([True, False])}\n",
    "        \n",
    "    elif clf == 'factorization-machines':\n",
    "        objective_metric_name = 'test:binary_classification_accuracy'\n",
    "        \n",
    "        hyperparameter_ranges = {'bias_wd': IntegerParameter(1, 1000)}\n",
    "        \n",
    "    tuner = HyperparameterTuner(est,\n",
    "                    objective_metric_name,\n",
    "                    hyperparameter_ranges,\n",
    "                    max_jobs=30,\n",
    "                    max_parallel_jobs=3)\n",
    "    \n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_job(clf):\n",
    "\n",
    "    # build the estimator\n",
    "    est = get_estimator(clf, sess, role)\n",
    "\n",
    "    # get the hyperparameter tuner config \n",
    "    if clf == 'xgboost':\n",
    "        \n",
    "        tuner = get_tuner(clf, est)\n",
    "        \n",
    "        \n",
    "        tuner.fit({'train': s3_input_train, 'validation': s3_input_validation}) \n",
    "\n",
    "    else:\n",
    "        # set the records\n",
    "        train_records = est.record_set(train_features, train_labels, channel='train')\n",
    "        test_records = est.record_set(test_features, test_labels, channel='validation')\n",
    "\n",
    "        tuner = get_tuner(clf, est)\n",
    "        \n",
    "        tuner.fit([train_records, test_records])\n",
    "    \n",
    "    \n",
    "run_training_job('linear-learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magic_loop(models_to_run):\n",
    "    pool = Pool(processes=multiprocessing.cpu_count())\n",
    "    transformed_rows = pool.map(run_training_job, models_to_run)\n",
    "    pool.close() \n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "client = boto3.client('sagemaker')\n",
    "bucket = 'ensemble-modeling'\n",
    "\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/train'.format(bucket), content_type='csv')\n",
    "s3_input_test = sagemaker.s3_input(s3_data='s3://{}/test/'.format(bucket), content_type='csv')\n",
    "\n",
    "# XGboost only likes a validation channel for hyperparameter tuning, not a test channel. So we'll set that up\n",
    "s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/validation/'.format(bucket), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define the models you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clfs = ['xgboost', 'linear-learner', 'factorization-machines', 'knn']\n",
    "\n",
    "clfs = [ 'xgboost']\n",
    "\n",
    "magic_loop(clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Select the best models\n",
    "Now, we're going to use SageMaker search to find the best performing models from the hyperparameter tuning jobs we just ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "smclient = boto3.client(service_name='sagemaker')\n",
    "\n",
    "# Search the training job by Amazon S3 location of model artifacts\n",
    "search_params={\n",
    "   \"MaxResults\": 100,\n",
    "   \"Resource\": \"TrainingJob\",\n",
    "   \"SearchExpression\": { \n",
    "      \"Filters\": [ \n",
    "         { \n",
    "            \"Name\": \"InputDataConfig.DataSource.S3DataSource.S3Uri\",\n",
    "            \"Operator\": \"Contains\",\n",
    "             \n",
    "             # set this to have a word that is in your bucket name\n",
    "            \"Value\": 'ensemble'\n",
    "         },\n",
    "        { \n",
    "            \"Name\": \"TrainingJobStatus\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": 'Completed'\n",
    "         }, \n",
    "    ],\n",
    "     \n",
    "   },\n",
    "    \n",
    "    \"SortBy\": \"Metrics.validation:auc\",\n",
    "    \"SortOrder\": \"Descending\"\n",
    "}\n",
    "results = smclient.search(**search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "def get_models(results):\n",
    "\n",
    "    role = sagemaker.get_execution_role()\n",
    "\n",
    "    models = []\n",
    "\n",
    "    for each in results['Results']:\n",
    "\n",
    "        job_name = each['TrainingJob']['TrainingJobName']\n",
    "\n",
    "\n",
    "        artifact = each['TrainingJob']['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "        # get training image\n",
    "        image =  each['TrainingJob']['AlgorithmSpecification']['TrainingImage']\n",
    "\n",
    "        m = Model(artifact, image, role = role, sagemaker_session = sess, name = job_name)\n",
    "\n",
    "        models.append(m)\n",
    "        \n",
    "    return models[:15]\n",
    "\n",
    "models = get_models(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Ensemble Batch Transform\n",
    "Now, we're going to run a separate batch transform job for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('actual_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4118, 60)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_data.drop('0', axis=1)\n",
    "\n",
    "test_df.to_csv('test_data.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./test_data.csv to s3://ensemble-modeling/batch_test/test.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp test_data.csv s3://ensemble-modeling/batch_test/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: xgboost-190730-1958-024-b8a2fd71\n"
     ]
    }
   ],
   "source": [
    "def run_batch_transform(model):\n",
    "\n",
    "    transformer = model.transformer(\n",
    "        instance_count=1,\n",
    "        instance_type='ml.m4.xlarge',\n",
    "        output_path='s3://ensemble-modeling/batch_results/{}'.format(model.name)\n",
    "    )\n",
    "\n",
    "    transformer.transform(data='s3://ensemble-modeling/batch_test/test.csv', content_type='text/csv')\n",
    "\n",
    "    \n",
    "for model in models:\n",
    "    run_batch_transform(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool = Pool(processes=multiprocessing.cpu_count())\n",
    "# transformed_rows = pool.map(run_batch_transform, models)\n",
    "# pool.close() \n",
    "# pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Consolidate batch results\n",
    "Finally, we'll pull together all of the batch job inferences. For each one, we'll take the maximum confidence level and consider that a positive prediction. Then we'll see how well that performs, relative to using a single XGBoost model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 sync s3://ensemble-modeling/batch_results/ /home/ec2-user/SageMaker/batch_results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_data['0'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(y_true):\n",
    "    \n",
    "    frames  = []\n",
    "    \n",
    "    for sub_dir in os.listdir('/home/ec2-user/SageMaker/batch_results'):\n",
    "        if '.ipynb' not in sub_dir:\n",
    "\n",
    "            old_file = '/home/ec2-user/SageMaker/batch_results/{}/test.csv.out'.format(sub_dir)\n",
    "            \n",
    "            new_file = '/home/ec2-user/SageMaker/batch_results/{}/test.csv'.format(sub_dir)\n",
    "            \n",
    "            os.system('cp {} {}'.format( old_file, new_file))\n",
    "            \n",
    "            df = pd.read_csv('/home/ec2-user/SageMaker/batch_results/{}/test.csv'.format(sub_dir), names = [sub_dir])\n",
    "\n",
    "            frames.append(df)\n",
    "            \n",
    "    df = pd.concat(frames, axis=1)\n",
    "    \n",
    "    df['y_true'] = y_true\n",
    "            \n",
    "    return df\n",
    "        \n",
    "df = get_dataframe(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_results(df):\n",
    "\n",
    "    df['max'] = 0\n",
    "    df['min'] = 0\n",
    "    df['diff'] = 0\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        top = max(row)\n",
    "        bottom = min(row)\n",
    "\n",
    "        diff = top - bottom\n",
    "\n",
    "\n",
    "        df.at[idx, 'max'] = top\n",
    "        df.at[idx, 'min'] = bottom\n",
    "        df.at[idx, 'diff'] = diff\n",
    "        \n",
    "    return df\n",
    "\n",
    "df = consolidate_results(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgboost-190730-2044-022-2352eede</th>\n",
       "      <th>xgboost-190730-2044-004-739de6d8</th>\n",
       "      <th>xgboost-190730-2020-030-483f572c</th>\n",
       "      <th>xgboost-190730-2020-029-b7c0ecf1</th>\n",
       "      <th>xgboost-190730-2044-005-b614948b</th>\n",
       "      <th>xgboost-190730-2044-019-440eba24</th>\n",
       "      <th>xgboost-190730-2020-028-3a863835</th>\n",
       "      <th>xgboost-190730-1958-021-72e38862</th>\n",
       "      <th>xgboost-190730-2020-019-c5dba7b3</th>\n",
       "      <th>xgboost-190730-2044-021-949ec8ac</th>\n",
       "      <th>xgboost-190730-1958-024-b8a2fd71</th>\n",
       "      <th>xgboost-190730-1958-023-2e4c37ce</th>\n",
       "      <th>xgboost-190730-1958-015-b671b4dc</th>\n",
       "      <th>xgboost-190730-2020-026-b0f76816</th>\n",
       "      <th>xgboost-190730-1958-013-578ad74a</th>\n",
       "      <th>y_true</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100188</td>\n",
       "      <td>0.103718</td>\n",
       "      <td>0.104903</td>\n",
       "      <td>0.098098</td>\n",
       "      <td>0.092084</td>\n",
       "      <td>0.092530</td>\n",
       "      <td>0.097160</td>\n",
       "      <td>0.098769</td>\n",
       "      <td>0.090717</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.074131</td>\n",
       "      <td>0.094674</td>\n",
       "      <td>0.086106</td>\n",
       "      <td>0.108009</td>\n",
       "      <td>0.089065</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.168533</td>\n",
       "      <td>0.176325</td>\n",
       "      <td>0.189338</td>\n",
       "      <td>0.208647</td>\n",
       "      <td>0.179116</td>\n",
       "      <td>0.182808</td>\n",
       "      <td>0.168847</td>\n",
       "      <td>0.195914</td>\n",
       "      <td>0.190306</td>\n",
       "      <td>0.171908</td>\n",
       "      <td>0.186766</td>\n",
       "      <td>0.141365</td>\n",
       "      <td>0.179298</td>\n",
       "      <td>0.210121</td>\n",
       "      <td>0.189402</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.282113</td>\n",
       "      <td>0.293109</td>\n",
       "      <td>0.251772</td>\n",
       "      <td>0.250157</td>\n",
       "      <td>0.254854</td>\n",
       "      <td>0.278672</td>\n",
       "      <td>0.256963</td>\n",
       "      <td>0.275336</td>\n",
       "      <td>0.270040</td>\n",
       "      <td>0.277161</td>\n",
       "      <td>0.251583</td>\n",
       "      <td>0.267924</td>\n",
       "      <td>0.222159</td>\n",
       "      <td>0.273822</td>\n",
       "      <td>0.242742</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040475</td>\n",
       "      <td>0.039072</td>\n",
       "      <td>0.035436</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.035632</td>\n",
       "      <td>0.038267</td>\n",
       "      <td>0.030731</td>\n",
       "      <td>0.028601</td>\n",
       "      <td>0.036439</td>\n",
       "      <td>0.040877</td>\n",
       "      <td>0.024260</td>\n",
       "      <td>0.031481</td>\n",
       "      <td>0.030913</td>\n",
       "      <td>0.021417</td>\n",
       "      <td>0.029594</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039658</td>\n",
       "      <td>0.038584</td>\n",
       "      <td>0.031971</td>\n",
       "      <td>0.029252</td>\n",
       "      <td>0.032894</td>\n",
       "      <td>0.037440</td>\n",
       "      <td>0.033342</td>\n",
       "      <td>0.028855</td>\n",
       "      <td>0.035477</td>\n",
       "      <td>0.040352</td>\n",
       "      <td>0.037843</td>\n",
       "      <td>0.040215</td>\n",
       "      <td>0.031937</td>\n",
       "      <td>0.031920</td>\n",
       "      <td>0.031521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   xgboost-190730-2044-022-2352eede  xgboost-190730-2044-004-739de6d8  \\\n",
       "0                          0.100188                          0.103718   \n",
       "1                          0.168533                          0.176325   \n",
       "2                          0.282113                          0.293109   \n",
       "3                          0.040475                          0.039072   \n",
       "4                          0.039658                          0.038584   \n",
       "\n",
       "   xgboost-190730-2020-030-483f572c  xgboost-190730-2020-029-b7c0ecf1  \\\n",
       "0                          0.104903                          0.098098   \n",
       "1                          0.189338                          0.208647   \n",
       "2                          0.251772                          0.250157   \n",
       "3                          0.035436                          0.026864   \n",
       "4                          0.031971                          0.029252   \n",
       "\n",
       "   xgboost-190730-2044-005-b614948b  xgboost-190730-2044-019-440eba24  \\\n",
       "0                          0.092084                          0.092530   \n",
       "1                          0.179116                          0.182808   \n",
       "2                          0.254854                          0.278672   \n",
       "3                          0.035632                          0.038267   \n",
       "4                          0.032894                          0.037440   \n",
       "\n",
       "   xgboost-190730-2020-028-3a863835  xgboost-190730-1958-021-72e38862  \\\n",
       "0                          0.097160                          0.098769   \n",
       "1                          0.168847                          0.195914   \n",
       "2                          0.256963                          0.275336   \n",
       "3                          0.030731                          0.028601   \n",
       "4                          0.033342                          0.028855   \n",
       "\n",
       "   xgboost-190730-2020-019-c5dba7b3  xgboost-190730-2044-021-949ec8ac  \\\n",
       "0                          0.090717                          0.098029   \n",
       "1                          0.190306                          0.171908   \n",
       "2                          0.270040                          0.277161   \n",
       "3                          0.036439                          0.040877   \n",
       "4                          0.035477                          0.040352   \n",
       "\n",
       "   xgboost-190730-1958-024-b8a2fd71  xgboost-190730-1958-023-2e4c37ce  \\\n",
       "0                          0.074131                          0.094674   \n",
       "1                          0.186766                          0.141365   \n",
       "2                          0.251583                          0.267924   \n",
       "3                          0.024260                          0.031481   \n",
       "4                          0.037843                          0.040215   \n",
       "\n",
       "   xgboost-190730-1958-015-b671b4dc  xgboost-190730-2020-026-b0f76816  \\\n",
       "0                          0.086106                          0.108009   \n",
       "1                          0.179298                          0.210121   \n",
       "2                          0.222159                          0.273822   \n",
       "3                          0.030913                          0.021417   \n",
       "4                          0.031937                          0.031920   \n",
       "\n",
       "   xgboost-190730-1958-013-578ad74a  y_true  max  min  diff  \n",
       "0                          0.089065       1    1    0     1  \n",
       "1                          0.189402       1    1    0     1  \n",
       "2                          0.242742       1    1    0     1  \n",
       "3                          0.029594       0    0    0     0  \n",
       "4                          0.031521       0    0    0     0  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Generate Confusion Matrix\n",
    "At the end, let's chart a plot for the performance of each of these models. Did the ensembling help? Which model appears to be the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results without ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.0%, Recall = 100.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predictions</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3595</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>389</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predictions   0.0  1.0\n",
       "actuals               \n",
       "0            3595   40\n",
       "1             389   94"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_confusion_matrix(df, model_column):\n",
    "    \n",
    "    mx = pd.crosstab(index=df['y_true'], columns=np.round(df[model_column]), rownames=['actuals'], colnames=['predictions'])\n",
    "\n",
    "    # lower right corner\n",
    "    tps = mx.iloc[1, 1]\n",
    "        \n",
    "    # upper right corner\n",
    "    fps = mx.iloc[0, 1]\n",
    "    \n",
    "    # lower left corner\n",
    "    fns = mx.iloc[1, 0]\n",
    "    \n",
    "    precision = np.round(tps / (tps + fns), 2) * 100\n",
    "    \n",
    "    recall = np.round(tps / (tps + fps), ) * 100\n",
    "    \n",
    "    print ('Precision = {}%, Recall = {}%'.format(precision, recall))\n",
    "    \n",
    "    return mx\n",
    "\n",
    "get_confusion_matrix(df,'xgboost-190730-2044-022-2352eede')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predictions</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3595</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>389</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predictions   0.0  1.0\n",
       "actuals               \n",
       "0            3595   40\n",
       "1             389   94"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One XGBoost model got us a precision of 0.7014925373134329 and recall of 0.19461697722567287\n"
     ]
    }
   ],
   "source": [
    "recall = 94 / (94 + 389)\n",
    "precision = 94 / (94 + 40)\n",
    "print ('One XGBoost model got us a precision of {} and recall of {}'.format(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predictions</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3635</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predictions     0    1\n",
       "actuals               \n",
       "0            3635    0\n",
       "1               0  483"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=df['y_true'], columns=np.round(df['max']), rownames=['actuals'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
